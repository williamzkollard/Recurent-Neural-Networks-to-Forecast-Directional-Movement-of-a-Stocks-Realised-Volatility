{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1min = pd.read_csv('AAPL_full_1min_adjsplit.csv')\n",
    "data_1min.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "data_1min['Date'] = pd.to_datetime(data_1min['Date'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "data_1hour = pd.read_csv('AAPL_full_1hour_adjsplit.csv')\n",
    "data_1hour.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "data_1min[\"Minute Log Return\"] = np.log(data_1min['Close']).diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72116</th>\n",
       "      <td>2024-01-19 15:00:00</td>\n",
       "      <td>191.6538</td>\n",
       "      <td>191.82</td>\n",
       "      <td>191.32</td>\n",
       "      <td>191.58</td>\n",
       "      <td>7353804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72117</th>\n",
       "      <td>2024-01-19 16:00:00</td>\n",
       "      <td>191.5600</td>\n",
       "      <td>191.61</td>\n",
       "      <td>191.32</td>\n",
       "      <td>191.55</td>\n",
       "      <td>10908684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72118</th>\n",
       "      <td>2024-01-19 17:00:00</td>\n",
       "      <td>191.5501</td>\n",
       "      <td>191.59</td>\n",
       "      <td>191.39</td>\n",
       "      <td>191.41</td>\n",
       "      <td>10460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72119</th>\n",
       "      <td>2024-01-19 18:00:00</td>\n",
       "      <td>191.4900</td>\n",
       "      <td>191.56</td>\n",
       "      <td>191.29</td>\n",
       "      <td>191.29</td>\n",
       "      <td>127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72120</th>\n",
       "      <td>2024-01-19 19:00:00</td>\n",
       "      <td>191.3000</td>\n",
       "      <td>191.31</td>\n",
       "      <td>191.10</td>\n",
       "      <td>191.31</td>\n",
       "      <td>15771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date      Open    High     Low   Close    Volume\n",
       "72116  2024-01-19 15:00:00  191.6538  191.82  191.32  191.58   7353804\n",
       "72117  2024-01-19 16:00:00  191.5600  191.61  191.32  191.55  10908684\n",
       "72118  2024-01-19 17:00:00  191.5501  191.59  191.39  191.41     10460\n",
       "72119  2024-01-19 18:00:00  191.4900  191.56  191.29  191.29    127000\n",
       "72120  2024-01-19 19:00:00  191.3000  191.31  191.10  191.31     15771"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1hour.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72120</th>\n",
       "      <td>2024-01-19 19:00:00</td>\n",
       "      <td>191.3</td>\n",
       "      <td>191.31</td>\n",
       "      <td>191.1</td>\n",
       "      <td>191.31</td>\n",
       "      <td>15771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date   Open    High    Low   Close  Volume\n",
       "72120  2024-01-19 19:00:00  191.3  191.31  191.1  191.31   15771"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1hour[data_1hour[\"Date\"] == \"2024-01-19 19:00:00\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_hourly_volatility(dataframe):\n",
    "   \n",
    "    # Convert 'Date' column to datetime if not already\n",
    "    if 'Date' in dataframe.columns and not pd.api.types.is_datetime64_any_dtype(dataframe['Date']):\n",
    "        dataframe['Date'] = pd.to_datetime(dataframe['Date'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Extract 'Date' and 'Minute_Log_Return' columns\n",
    "    date_log_return_df = dataframe[['Date', 'Minute Log Return']]\n",
    "\n",
    "    # Set 'Date' as the index\n",
    "    date_log_return_df.set_index('Date', inplace=True)\n",
    "\n",
    "    #Scaled volatility    \n",
    "    hourly_volatility = date_log_return_df.resample('H').apply(lambda x: (x ** 2).sum(axis=0)).apply(lambda x: x ** 0.5)\n",
    "    hourly_volatility.reset_index(inplace=True)\n",
    "    hourly_volatility.columns = ['Date', 'Hourly_Volatility']\n",
    "\n",
    "    return hourly_volatility\n",
    "\n",
    "\n",
    "result_df = calculate_hourly_volatility(data_1min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Date  Hourly_Volatility\n",
      "0      2005-01-03 08:00:00           0.010816\n",
      "1      2005-01-03 09:00:00           0.018272\n",
      "2      2005-01-03 10:00:00           0.010737\n",
      "3      2005-01-03 11:00:00           0.005680\n",
      "4      2005-01-03 12:00:00           0.004975\n",
      "...                    ...                ...\n",
      "167887 2024-02-28 15:00:00           0.002420\n",
      "167888 2024-02-28 16:00:00           0.002219\n",
      "167889 2024-02-28 17:00:00           0.002406\n",
      "167890 2024-02-28 18:00:00           0.001517\n",
      "167891 2024-02-28 19:00:00           0.001255\n",
      "\n",
      "[72397 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def remove_zero_volatility(dataframe):\n",
    "\n",
    "    # Filter rows where 'Intraday_Volatility' is not zero\n",
    "    filtered_dataframe = dataframe[dataframe['Hourly_Volatility'] != 0]\n",
    "\n",
    "    return filtered_dataframe\n",
    "\n",
    "# Remove rows with zero intraday volatility\n",
    "filtered_result_df = remove_zero_volatility(result_df)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(filtered_result_df)\n",
    "newresults = filtered_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_17451/1952436155.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Date'] = pd.to_datetime(df1['Date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def synchronize_dataframes_by_date(df1, df2):\n",
    "\n",
    "    df1['Date'] = pd.to_datetime(df1['Date'], errors='coerce')\n",
    "    df2['Date'] = pd.to_datetime(df2['Date'], errors='coerce')\n",
    "\n",
    "    # Identify common dates by merging on the 'Date' column\n",
    "    common_dates = pd.merge(df1[['Date']], df2[['Date']], on='Date', how='inner')\n",
    "    \n",
    "    # Filter both dataframes to only include the common dates\n",
    "    df1_sync = df1[df1['Date'].isin(common_dates['Date'])]\n",
    "    df2_sync = df2[df2['Date'].isin(common_dates['Date'])]\n",
    "\n",
    "    return df1_sync, df2_sync\n",
    "\n",
    "newresults_sync, data_1hour_sync = synchronize_dataframes_by_date(newresults, data_1hour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_17451/2225684696.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1hour_sync['Date'] = pd.to_datetime(data_1hour_sync['Date'])\n",
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_17451/2225684696.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newresults_sync['Date'] = pd.to_datetime(newresults_sync['Date'])\n"
     ]
    }
   ],
   "source": [
    "data_1hour_sync['Date'] = pd.to_datetime(data_1hour_sync['Date'])\n",
    "newresults_sync['Date'] = pd.to_datetime(newresults_sync['Date'])\n",
    "data_1hour_sync.set_index('Date', inplace=True)\n",
    "newresults_sync.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_17451/2337339055.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1hour_sync[\"Hourly Volatility\"] = newresults_sync[\"Hourly_Volatility\"]\n"
     ]
    }
   ],
   "source": [
    "data_1hour_sync[\"Hourly Volatility\"] = newresults_sync[\"Hourly_Volatility\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_17451/68887939.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1hour_sync['Range'] = data_1hour_sync['High'] - data_1hour_sync['Low']\n",
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_17451/68887939.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1hour_sync['Return'] = np.log(data_1hour_sync['Close']).diff()\n",
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_17451/68887939.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1hour_sync['Return_Squared'] = np.square(data_1hour_sync['Return'])\n"
     ]
    }
   ],
   "source": [
    "data_1hour_sync['Range'] = data_1hour_sync['High'] - data_1hour_sync['Low']\n",
    "data_1hour_sync['Return'] = np.log(data_1hour_sync['Close']).diff()\n",
    "data_1hour_sync['Return_Squared'] = np.square(data_1hour_sync['Return'])\n",
    "data_1hour_sync = data_1hour_sync.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas_ta in /Users/williamkollard/anaconda3/envs/diss_model/lib/python3.9/site-packages (0.3.14b0)\n",
      "Requirement already satisfied: pandas in /Users/williamkollard/anaconda3/envs/diss_model/lib/python3.9/site-packages (from pandas_ta) (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/williamkollard/anaconda3/envs/diss_model/lib/python3.9/site-packages (from pandas->pandas_ta) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/williamkollard/anaconda3/envs/diss_model/lib/python3.9/site-packages (from pandas->pandas_ta) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/williamkollard/anaconda3/envs/diss_model/lib/python3.9/site-packages (from pandas->pandas_ta) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/williamkollard/anaconda3/envs/diss_model/lib/python3.9/site-packages (from pandas->pandas_ta) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/williamkollard/anaconda3/envs/diss_model/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_1hour_sync.dropna()\n",
    "hourly_volatility = data[\"Hourly Volatility\"]\n",
    "df = pd.DataFrame({'hourly_volatility': hourly_volatility})\n",
    "\n",
    "# Create a new column based on the conditions\n",
    "df['target'] = np.where(df['hourly_volatility'] > df['hourly_volatility'].shift(1), 1, 0)\n",
    "\n",
    "# The first day has no previous day to compare, so set the signal to 0\n",
    "df['target'].fillna(0, inplace=True)\n",
    "data['target'] = df['target']\n",
    "data_full = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = data_full[[\"Return_Squared\", \"Hourly Volatility\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.to_csv(r\"Intrahour Volatility Dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss_model",
   "language": "python",
   "name": "diss_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
