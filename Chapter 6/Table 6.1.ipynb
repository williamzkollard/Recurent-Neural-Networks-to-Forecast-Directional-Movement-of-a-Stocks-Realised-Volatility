{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate, Bidirectional, GRU \n",
    "from keras import Model\n",
    "from keras import optimizers\n",
    "from tensorflow import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = pd.read_csv('Intrahour Volatility Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_full[[\"Return_Squared\", \"Hourly Volatility\"]]\n",
    "Y = data_full[\"target\"]\n",
    "data_set = data_full[[\"Date\",\"Return_Squared\", \"Hourly Volatility\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitlimit = int(len(data_full)*0.8)\n",
    "training_features, test_data = data_set[:splitlimit], data_set[splitlimit:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_18281/1338683924.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_features[\"hourly_volatility_rolling_median\"] = training_features[\"Hourly Volatility\"].rolling(window=41, center=True, min_periods=1).median()\n",
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_18281/1338683924.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_features[\"return_squared_rolling_median\"] = training_features[\"Return_Squared\"].rolling(window=41, center=True, min_periods=1).median()\n",
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_18281/1338683924.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_features[\"volatility minus median\"] = (training_features[\"Hourly Volatility\"] - training_features[\"hourly_volatility_rolling_median\"]).abs()\n",
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_18281/1338683924.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_features[\"return minus median\"] = (training_features[\"Return_Squared\"] - training_features[\"return_squared_rolling_median\"]).abs()\n"
     ]
    }
   ],
   "source": [
    "#Outlier Detection in training_data_features\n",
    "\n",
    "training_features[\"hourly_volatility_rolling_median\"] = training_features[\"Hourly Volatility\"].rolling(window=41, center=True, min_periods=1).median()\n",
    "training_features[\"return_squared_rolling_median\"] = training_features[\"Return_Squared\"].rolling(window=41, center=True, min_periods=1).median()\n",
    "training_features[\"volatility minus median\"] = (training_features[\"Hourly Volatility\"] - training_features[\"hourly_volatility_rolling_median\"]).abs()\n",
    "training_features[\"return minus median\"] = (training_features[\"Return_Squared\"] - training_features[\"return_squared_rolling_median\"]).abs()\n",
    "volatility_outliers_removed = training_features[~(training_features['volatility minus median'] > 5 * training_features['volatility minus median'].median())]\n",
    "both_outliers_removed = volatility_outliers_removed[~(volatility_outliers_removed['return minus median'] > 5 * volatility_outliers_removed['return minus median'].median())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = both_outliers_removed[[\"Return_Squared\", \"Hourly Volatility\"]]\n",
    "Y_cleaned = both_outliers_removed[\"target\"]\n",
    "data_set_cleaned = both_outliers_removed[[\"Return_Squared\", \"Hourly Volatility\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "training_data_features_scaled = scaler.fit_transform(X_cleaned)\n",
    "data_set_scaled = scaler.fit_transform(data_set_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reconstructing training data\n",
    "Z = []\n",
    "\n",
    "backcandles = 15\n",
    "\n",
    "for j in range(2):\n",
    "    Z.append([])\n",
    "    for i in range(backcandles, training_data_features_scaled.shape[0]):\n",
    "        Z[j].append(training_data_features_scaled[i-backcandles:i, j])\n",
    "        \n",
    "Z = np.moveaxis(Z, [0], [2])    \n",
    "Z, yi = np.array(Z), np.array(data_set_scaled[backcandles-1:, -1])\n",
    "y_final = np.reshape(yi,(len(yi),1))\n",
    "y_final = y_final[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.6456 - accuracy: 0.6190 - val_loss: 0.6154 - val_accuracy: 0.6550\n",
      "Epoch 2/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.6108 - accuracy: 0.6644 - val_loss: 0.6022 - val_accuracy: 0.6755\n",
      "Epoch 3/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.6019 - accuracy: 0.6712 - val_loss: 0.5977 - val_accuracy: 0.6767\n",
      "Epoch 4/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.6000 - accuracy: 0.6736 - val_loss: 0.5961 - val_accuracy: 0.6780\n",
      "Epoch 5/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5984 - accuracy: 0.6750 - val_loss: 0.5961 - val_accuracy: 0.6774\n",
      "Epoch 6/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5972 - accuracy: 0.6770 - val_loss: 0.5960 - val_accuracy: 0.6793\n",
      "Epoch 7/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5962 - accuracy: 0.6769 - val_loss: 0.5964 - val_accuracy: 0.6774\n",
      "Epoch 8/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5951 - accuracy: 0.6798 - val_loss: 0.5957 - val_accuracy: 0.6802\n",
      "Epoch 9/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5942 - accuracy: 0.6791 - val_loss: 0.5928 - val_accuracy: 0.6794\n",
      "Epoch 10/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5935 - accuracy: 0.6778 - val_loss: 0.5915 - val_accuracy: 0.6806\n",
      "Epoch 11/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5921 - accuracy: 0.6813 - val_loss: 0.5909 - val_accuracy: 0.6804\n",
      "Epoch 12/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5911 - accuracy: 0.6809 - val_loss: 0.5887 - val_accuracy: 0.6848\n",
      "Epoch 13/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5902 - accuracy: 0.6810 - val_loss: 0.5880 - val_accuracy: 0.6842\n",
      "Epoch 14/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5887 - accuracy: 0.6835 - val_loss: 0.5877 - val_accuracy: 0.6824\n",
      "Epoch 15/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5878 - accuracy: 0.6834 - val_loss: 0.5868 - val_accuracy: 0.6834\n",
      "Epoch 16/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5871 - accuracy: 0.6849 - val_loss: 0.5867 - val_accuracy: 0.6851\n",
      "Epoch 17/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5861 - accuracy: 0.6868 - val_loss: 0.5864 - val_accuracy: 0.6844\n",
      "Epoch 18/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5855 - accuracy: 0.6854 - val_loss: 0.5828 - val_accuracy: 0.6888\n",
      "Epoch 19/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5846 - accuracy: 0.6856 - val_loss: 0.5818 - val_accuracy: 0.6889\n",
      "Epoch 20/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5841 - accuracy: 0.6869 - val_loss: 0.5803 - val_accuracy: 0.6906\n"
     ]
    }
   ],
   "source": [
    "lstm_input = Input(shape = (backcandles, 2), name = 'lstm_input')\n",
    "\n",
    "inputs = LSTM(80, name='first_layer')(lstm_input)\n",
    "\n",
    "inputs = Dense(1, name='dense_layer')(inputs)\n",
    "\n",
    "output = Activation('sigmoid', name = 'output')(inputs)\n",
    "\n",
    "model = Model(inputs = lstm_input, outputs = output)\n",
    "model.compile(optimizer=\"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "start_time = time.time()\n",
    "history = model.fit(x=Z, y=y_final, epochs = 20, validation_data = (Z, y_final))\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_input (InputLayer)      [(None, 15, 2)]           0         \n",
      "_________________________________________________________________\n",
      "first_layer (LSTM)           (None, 80)                26560     \n",
      "_________________________________________________________________\n",
      "dense_layer (Dense)          (None, 1)                 81        \n",
      "_________________________________________________________________\n",
      "output (Activation)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 26,641\n",
      "Trainable params: 26,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1349/1349 [==============================] - 0s 177us/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "101.37127017974854\n",
      "[0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# Evaluate the model on the test data\n",
    "training_accuracy = model.evaluate(Z)\n",
    "\n",
    "print(training_time)\n",
    "print(training_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1349/1349 [==============================] - 5s 3ms/step - loss: 0.6348 - accuracy: 0.6344 - val_loss: 0.6150 - val_accuracy: 0.6645\n",
      "Epoch 2/20\n",
      "1349/1349 [==============================] - 4s 3ms/step - loss: 0.6103 - accuracy: 0.6637 - val_loss: 0.6093 - val_accuracy: 0.6630\n",
      "Epoch 3/20\n",
      "1349/1349 [==============================] - 4s 3ms/step - loss: 0.6032 - accuracy: 0.6713 - val_loss: 0.5981 - val_accuracy: 0.6761\n",
      "Epoch 4/20\n",
      "1349/1349 [==============================] - 4s 3ms/step - loss: 0.6002 - accuracy: 0.6737 - val_loss: 0.5999 - val_accuracy: 0.6742\n",
      "Epoch 5/20\n",
      "1349/1349 [==============================] - 5s 3ms/step - loss: 0.5986 - accuracy: 0.6745 - val_loss: 0.5960 - val_accuracy: 0.6792\n",
      "Epoch 6/20\n",
      "1349/1349 [==============================] - 4s 3ms/step - loss: 0.5976 - accuracy: 0.6751 - val_loss: 0.5988 - val_accuracy: 0.6777\n",
      "Epoch 7/20\n",
      "1349/1349 [==============================] - 4s 3ms/step - loss: 0.5961 - accuracy: 0.6775 - val_loss: 0.5934 - val_accuracy: 0.6803\n",
      "Epoch 8/20\n",
      "1349/1349 [==============================] - 4s 3ms/step - loss: 0.5951 - accuracy: 0.6789 - val_loss: 0.5939 - val_accuracy: 0.6805\n",
      "Epoch 9/20\n",
      "1349/1349 [==============================] - 4s 3ms/step - loss: 0.5939 - accuracy: 0.6815 - val_loss: 0.5925 - val_accuracy: 0.6793\n",
      "Epoch 10/20\n",
      "1349/1349 [==============================] - 5s 3ms/step - loss: 0.5926 - accuracy: 0.6810 - val_loss: 0.5901 - val_accuracy: 0.6836\n",
      "Epoch 11/20\n",
      "1349/1349 [==============================] - 4s 3ms/step - loss: 0.5917 - accuracy: 0.6823 - val_loss: 0.5894 - val_accuracy: 0.6840\n",
      "Epoch 12/20\n",
      "1349/1349 [==============================] - 4s 3ms/step - loss: 0.5906 - accuracy: 0.6815 - val_loss: 0.5891 - val_accuracy: 0.6842\n",
      "Epoch 13/20\n",
      "1349/1349 [==============================] - 5s 3ms/step - loss: 0.5898 - accuracy: 0.6822 - val_loss: 0.5872 - val_accuracy: 0.6868\n",
      "Epoch 14/20\n",
      "1349/1349 [==============================] - 5s 3ms/step - loss: 0.5885 - accuracy: 0.6851 - val_loss: 0.5877 - val_accuracy: 0.6862\n",
      "Epoch 15/20\n",
      "1349/1349 [==============================] - 5s 3ms/step - loss: 0.5876 - accuracy: 0.6852 - val_loss: 0.5854 - val_accuracy: 0.6862\n",
      "Epoch 16/20\n",
      "1349/1349 [==============================] - 5s 3ms/step - loss: 0.5867 - accuracy: 0.6868 - val_loss: 0.5840 - val_accuracy: 0.6884\n",
      "Epoch 17/20\n",
      "1349/1349 [==============================] - 5s 3ms/step - loss: 0.5858 - accuracy: 0.6861 - val_loss: 0.5826 - val_accuracy: 0.6879\n",
      "Epoch 18/20\n",
      "1349/1349 [==============================] - 5s 3ms/step - loss: 0.5849 - accuracy: 0.6883 - val_loss: 0.5820 - val_accuracy: 0.6893\n",
      "Epoch 19/20\n",
      "1349/1349 [==============================] - 5s 3ms/step - loss: 0.5839 - accuracy: 0.6888 - val_loss: 0.5809 - val_accuracy: 0.6910\n",
      "Epoch 20/20\n",
      "1349/1349 [==============================] - 5s 4ms/step - loss: 0.5828 - accuracy: 0.6887 - val_loss: 0.5810 - val_accuracy: 0.6921\n"
     ]
    }
   ],
   "source": [
    "gru_input = Input(shape = (backcandles, 2), name = 'gru_input')\n",
    "\n",
    "inputs = GRU(80, name='first_layer')(gru_input)\n",
    "\n",
    "inputs = Dense(1, name='dense_layer')(inputs)\n",
    "\n",
    "output = Activation('sigmoid', name = 'output')(inputs)\n",
    "\n",
    "model2 = Model(inputs = gru_input, outputs = output)\n",
    "model2.compile(optimizer=\"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "start_time2 = time.time()\n",
    "history2 = model2.fit(x=Z, y=y_final, epochs = 20, validation_data = (Z, y_final))\n",
    "end_time2 = time.time()\n",
    "training_time2 = end_time2 - start_time2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_input (InputLayer)       [(None, 15, 2)]           0         \n",
      "_________________________________________________________________\n",
      "first_layer (GRU)            (None, 80)                20160     \n",
      "_________________________________________________________________\n",
      "dense_layer (Dense)          (None, 1)                 81        \n",
      "_________________________________________________________________\n",
      "output (Activation)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 20,241\n",
      "Trainable params: 20,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "91.04903197288513\n"
     ]
    }
   ],
   "source": [
    "model2.summary()\n",
    "print(training_time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data[[\"Return_Squared\", \"Hourly Volatility\"]]\n",
    "Y_test = test_data[\"target\"]\n",
    "test_dataset = test_data[[\"Return_Squared\", \"Hourly Volatility\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling test data\n",
    "test_scaled = scaler.fit_transform(test_dataset)\n",
    "X_test_scaled = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reconstructing test data\n",
    "T = []\n",
    "\n",
    "backcandles = 15\n",
    "\n",
    "for j in range(2):\n",
    "    T.append([])\n",
    "    for i in range(backcandles, X_test_scaled.shape[0]):\n",
    "        T[j].append(X_test_scaled[i-backcandles:i, j])\n",
    "        \n",
    "T = np.moveaxis(T, [0], [2])\n",
    "T, yi_test = np.array(T), np.array(test_scaled[backcandles-1:, -1])\n",
    "y_final_test = np.reshape(yi_test,(len(yi_test),1))\n",
    "y_final_test = y_final_test[1:]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions1 = model.predict(T)\n",
    "test_predicted_classes1 = (test_predictions1 > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5314 1459]\n",
      " [2753 4852]]\n"
     ]
    }
   ],
   "source": [
    "#lstm\n",
    "test_predictions1 = model.predict(T)\n",
    "test_predicted_classes1 = (test_predictions1 > 0.5).astype(int)\n",
    "dataframe = pd.DataFrame(y_final_test, columns = [\"target\"])\n",
    "dataframe[\"predicted\"] = test_predicted_classes1\n",
    "cm_lstm = confusion_matrix(dataframe['predicted'], dataframe['target'])\n",
    "print(cm_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5214 1257]\n",
      " [2853 5054]]\n"
     ]
    }
   ],
   "source": [
    "#gru\n",
    "test_predictions2 = model2.predict(T)\n",
    "test_predicted_classes2 = (test_predictions2 > 0.5).astype(int)\n",
    "dataframe2 = pd.DataFrame(y_final_test, columns = [\"target\"])\n",
    "dataframe2[\"predicted\"] = test_predicted_classes2\n",
    "cm_gru = confusion_matrix(dataframe2['predicted'], dataframe2['target'])\n",
    "print(cm_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss_model",
   "language": "python",
   "name": "diss_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
