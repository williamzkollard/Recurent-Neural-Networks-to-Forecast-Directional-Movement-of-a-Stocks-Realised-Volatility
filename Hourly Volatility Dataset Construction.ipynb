{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1min = pd.read_csv('AAPL_full_1min_adjsplit.csv')\n",
    "data_1min.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "data_1min['Date'] = pd.to_datetime(data_1min['Date'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "data_1hour = pd.read_csv('AAPL_full_1hour_adjsplit.csv')\n",
    "data_1hour.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "data_1min[\"Minute Log Return\"] = np.log(data_1min['Close']).diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_4555/802173827.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  hourly_volatility = date_log_return_df.resample('H').apply(lambda x: (x ** 2).sum(axis=0) / x.notna().sum(axis=0)).apply(lambda x: x ** 0.5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_hourly_volatility(dataframe):\n",
    "   \n",
    "    # Convert 'Date' column to datetime if not already\n",
    "    if 'Date' in dataframe.columns and not pd.api.types.is_datetime64_any_dtype(dataframe['Date']):\n",
    "        dataframe['Date'] = pd.to_datetime(dataframe['Date'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Extract 'Date' and 'Minute_Log_Return' columns\n",
    "    date_log_return_df = dataframe[['Date', 'Minute Log Return']]\n",
    "\n",
    "    # Set 'Date' as the index\n",
    "    date_log_return_df.set_index('Date', inplace=True)\n",
    "\n",
    "    #Scaled volatility\n",
    "    hourly_volatility = date_log_return_df.resample('H').apply(lambda x: (x ** 2).sum(axis=0) / x.notna().sum(axis=0)).apply(lambda x: x ** 0.5)\n",
    "\n",
    "    hourly_volatility.reset_index(inplace=True)\n",
    "    hourly_volatility.columns = ['Date', 'Hourly_Volatility']\n",
    "\n",
    "    return hourly_volatility\n",
    "\n",
    "\n",
    "result_df = calculate_hourly_volatility(data_1min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Date  Hourly_Volatility\n",
      "0      2005-01-03 08:00:00           0.001755\n",
      "1      2005-01-03 09:00:00           0.002889\n",
      "2      2005-01-03 10:00:00           0.001386\n",
      "3      2005-01-03 11:00:00           0.000733\n",
      "4      2005-01-03 12:00:00           0.000642\n",
      "...                    ...                ...\n",
      "167887 2024-02-28 15:00:00           0.000312\n",
      "167888 2024-02-28 16:00:00           0.000297\n",
      "167889 2024-02-28 17:00:00           0.000376\n",
      "167890 2024-02-28 18:00:00           0.000249\n",
      "167891 2024-02-28 19:00:00           0.000241\n",
      "\n",
      "[167735 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "def remove_zero_volatility(dataframe):\n",
    "\n",
    "    # Filter rows where 'Intraday_Volatility' is not zero\n",
    "    filtered_dataframe = dataframe[dataframe['Hourly_Volatility'] != 0]\n",
    "\n",
    "    return filtered_dataframe\n",
    "\n",
    "# Remove rows with zero intraday volatility\n",
    "filtered_result_df = remove_zero_volatility(result_df)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(filtered_result_df)\n",
    "newresults = filtered_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_4555/1952436155.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Date'] = pd.to_datetime(df1['Date'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def synchronize_dataframes_by_date(df1, df2):\n",
    "\n",
    "    df1['Date'] = pd.to_datetime(df1['Date'], errors='coerce')\n",
    "    df2['Date'] = pd.to_datetime(df2['Date'], errors='coerce')\n",
    "\n",
    "    # Identify common dates by merging on the 'Date' column\n",
    "    common_dates = pd.merge(df1[['Date']], df2[['Date']], on='Date', how='inner')\n",
    "    \n",
    "    # Filter both dataframes to only include the common dates\n",
    "    df1_sync = df1[df1['Date'].isin(common_dates['Date'])]\n",
    "    df2_sync = df2[df2['Date'].isin(common_dates['Date'])]\n",
    "\n",
    "    return df1_sync, df2_sync\n",
    "\n",
    "newresults_sync, data_1hour_sync = synchronize_dataframes_by_date(newresults, data_1hour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_4555/2225684696.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1hour_sync['Date'] = pd.to_datetime(data_1hour_sync['Date'])\n",
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_4555/2225684696.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  newresults_sync['Date'] = pd.to_datetime(newresults_sync['Date'])\n"
     ]
    }
   ],
   "source": [
    "data_1hour_sync['Date'] = pd.to_datetime(data_1hour_sync['Date'])\n",
    "newresults_sync['Date'] = pd.to_datetime(newresults_sync['Date'])\n",
    "data_1hour_sync.set_index('Date', inplace=True)\n",
    "newresults_sync.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_4555/2337339055.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1hour_sync[\"Hourly Volatility\"] = newresults_sync[\"Hourly_Volatility\"]\n"
     ]
    }
   ],
   "source": [
    "data_1hour_sync[\"Hourly Volatility\"] = newresults_sync[\"Hourly_Volatility\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_4555/68887939.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1hour_sync['Range'] = data_1hour_sync['High'] - data_1hour_sync['Low']\n",
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_4555/68887939.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1hour_sync['Return'] = np.log(data_1hour_sync['Close']).diff()\n",
      "/var/folders/cb/9kkmszhd7fx9_93t2qb1_s640000gn/T/ipykernel_4555/68887939.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_1hour_sync['Return_Squared'] = np.square(data_1hour_sync['Return'])\n"
     ]
    }
   ],
   "source": [
    "data_1hour_sync['Range'] = data_1hour_sync['High'] - data_1hour_sync['Low']\n",
    "data_1hour_sync['Return'] = np.log(data_1hour_sync['Close']).diff()\n",
    "data_1hour_sync['Return_Squared'] = np.square(data_1hour_sync['Return'])\n",
    "data_1hour_sync = data_1hour_sync.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas_ta in /Users/williamkollard/anaconda3/envs/diss_model/lib/python3.9/site-packages (0.3.14b0)\n",
      "Requirement already satisfied: pandas in /Users/williamkollard/anaconda3/envs/diss_model/lib/python3.9/site-packages (from pandas_ta) (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/williamkollard/anaconda3/envs/diss_model/lib/python3.9/site-packages (from pandas->pandas_ta) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/williamkollard/anaconda3/envs/diss_model/lib/python3.9/site-packages (from pandas->pandas_ta) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/williamkollard/anaconda3/envs/diss_model/lib/python3.9/site-packages (from pandas->pandas_ta) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/williamkollard/anaconda3/envs/diss_model/lib/python3.9/site-packages (from pandas->pandas_ta) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/williamkollard/anaconda3/envs/diss_model/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas_ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_1hour_sync.dropna()\n",
    "hourly_volatility = data[\"Hourly Volatility\"]\n",
    "df = pd.DataFrame({'hourly_volatility': hourly_volatility})\n",
    "\n",
    "# Create a new column based on the conditions\n",
    "df['target'] = np.where(df['hourly_volatility'] > df['hourly_volatility'].shift(1), 1, 0)\n",
    "\n",
    "# The first day has no previous day to compare, so set the signal to 0\n",
    "df['target'].fillna(0, inplace=True)\n",
    "data['target'] = df['target']\n",
    "data_full = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = data_full[[\"Return_Squared\", \"Hourly Volatility\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full.to_csv(r\"Hourly Volatility Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss_model",
   "language": "python",
   "name": "diss_model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
